# Experiment 2: Replication of Dijkgraaf et al.'s (2017) visual world experiment

This branch contains all the scripts and resources needed to implement Experiment 2 of Slim and Hartsuiker's paper *Moving visual world experiments online? 
A web-based replication of Dijkgraaf, Hartsuiker, and Ducyk (2017) using PCIbex and WebGazer.js*. This expriment is a replication of Dijkgraaf, Hartsuiker, and Duyck's (2017) visual world experiment. The aim of this experiment is to test predictive processing at the verb in English sentence comprehension. The participants passively listen to sentences while they look at four images, arranged in the four quadrants of the display. 

The experiment is implemented in PCIbex (Zehr & Schwarz, 2018). The script is most recently tested in PCIbex 2.0.  The calibration procedure in this newer version of PCibex is slightly different than described in the paper. However, the underlying logic of the calibration is similar. I cannot garantuee that I will maintain the script up-to-date to be used in the later versions of PCIbex. However, if you have any questions or spot any bugs, please get in touch via <mieke.slim@ugent.be>, and I will do my best to troubleshoot. 

Please note that this script requires some understanding of how PCIbex works. If you want to use this script, it is highly recommended to first study the PCIbex documentation ([https://doc.pcibex.net/](https://doc.pcibex.net/)), go through both the [basic](https://doc.pcibex.net/basic-tutorial/) and [advanced](https://doc.pcibex.net/advanced-tutorial/) tutorials, and study the [how-to guide on collecting eye tracking data](https://doc.pcibex.net/how-to-guides/collecting-eyetracking-data/) written by the PCIbex developers.
